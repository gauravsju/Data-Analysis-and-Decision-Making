---
title: 'Confidence Intervals and Prediction Intervals using R'
author: "Jayendra Bhardwaj"
---


```{r}
library("faraway") 
library("ellipse")
library("scatterplot3d")
library("rgl")
library("printr")
```


- Consider the **savings** data from the **faraway** package

```{r}
library("faraway")
data(savings)
head(savings)
```

- Fit the linear model using all the predictors

```{r}
g <- lm(sr ~ ., savings)
summary(g)
```

### Individual CI's, Manual Method  

- This is the _manual method_ for the coefficients, which means we need to understand the formula for the confidence interval.

- We will not use the formulas to compute the least squares estimates and their standard errors, rather we will take the values from the computed output, which are, for each coefficient:
    + The estimate of the each $\beta$ coefficient
    + The estimate of the *standand error of estimate*

```{r}
(cf <- summary(g)$coef)
```

- `cf` is a data.frame
- We need to decide on the *level of confidence*, in this case we choose it to be 95%
- This leaves 5% to be split between the two tails of the t-distribution with the appropriate degrees of freedom
- The degrees of freedom for residual are $50-5=45$ 
- The *standard errors* are second column of `cf`

```{r, results='hold'}
df.residual(g)
(alpha <- (1-.95))
(t.crit <- qt(1-alpha/2, df.residual(g)))
cf[,"Std. Error"]
```

>The basic pattern of a confidence interval is:
$$lower = estimte - t.crit*standard.error.of.estimate$$
$$upper = estimte + t.crit*standard.error.of.estimate$$

```{r}
pop15_95 <- 
  c(cf["pop15", "Estimate"] - t.crit*cf["pop15", "Std. Error"], 
    cf["pop15", "Estimate"] + t.crit*cf["pop15", "Std. Error"])

pop75_95 <- 
  c(cf["pop75", "Estimate"] - t.crit*cf["pop75", "Std. Error"], 
    cf["pop75", "Estimate"] + t.crit*cf["pop75", "Std. Error"])

dpi_95 <- 
  c(cf["dpi", "Estimate"] - t.crit*cf["dpi", "Std. Error"], 
    cf["dpi", "Estimate"] + t.crit*cf["dpi", "Std. Error"])

ddpi_95 <- 
  c(cf["ddpi", "Estimate"] - t.crit*cf["ddpi", "Std. Error"], 
    cf["ddpi", "Estimate"] + t.crit*cf["ddpi", "Std. Error"])
```

Let's put all these confidence intervals into a matrix and print it out.

```{r}
conf_int <- rbind(pop15_95, pop75_95, dpi_95, ddpi_95)
colnames(conf_int) <- c("lower 2.5%", "upper 97.5%")
conf_int
```

### Individual CI's, Automatic Method  

Wow! That was a lot of work! So now we turn to an easier way to get individual CI's.

```{r}
confint(g)
```

### Things to Remember about Individual CI's 

- Strict practice of Individual 95% CI is defined just to use only one CI, not two or more of the 95% CI's simulaneously

- Therefore, we need to decide in advance which 95% CI we will use

- This is the only way we can then claim to have a 95% confidence level

- For some statistical claims, this is all that is needed; e.g. in sexual bias cases we are only interested in the 95% CI of the coefficient for the sex effect 

- For another example, studies of ROI are interested only in the 95% CI of the rate of return for each unit invested

### Other Levels of Confidence  

- We can get the CI's for other levels of confidence.

- This will be useful for implementling the _Bonferroni Correction_

- Note that as the level of confidence increases, so does the width of the CI

```{r}
# - 95% is default, use "level = " option for other confidence levels, e.g. 99%
confint(g, level = 0.99)
```

## Joint Confidence Region (CR)  

- We illustrate the joint 95% CR for just two parameters (e.g. **ddpi** and **pop75**), since we want to see a graph of the CR. 

- Here are the keys things we need to consider:
    + _Remember that the estimates of the coefficients are random variables_
    + _Estimates of two or more coefficients are usually correlated_
    + _The joint distribution of coefficient estimates is approximately multivariate normal due to the **Central Limit Theorem**_

- Some points about the joint CR:
    + _We get an elliptical 95% CR by taking the 95% contour of the density of the multivariate normal distribution_
    + _The total area under the density surface is 100%_
    + _The 3D volume under the density surface and bounded by the cylinder of the CR is 95%_
    + _Imagine a cake (soufle?) with a mound in the center, before it cools_

```{r}
plot(ellipse(g, c("pop15", "pop75")), 
     type = "l", 
     xlim = c(-1,0),
     main = "Joint Confidence Region")
points(0,0)
points(coef(g)["pop15"], coef(g)["pop75"], 
       pch=18)
abline(v=confint(g)["pop15",], lty=2)
abline(h=confint(g)["pop75",], lty=2)
```

- Look at the area _inside_ the CR but _outside_ both CI's:
    + The CR would claim these values are probable for the coefficients
    + But the simultanious 95% CI's would say these values are improbable

- Look in the area _outside_ the CR but _inside_ both CI's:
    + The CR would claim these values are improbabable for the coeffcienets
    + The simultaneous 95% CI's would say these values are probable

### Joint CR and Simultaneous CI's lead to different Hypothesis Testing Conclusions

```{r}
plot(ellipse(g, c("pop15", "pop75")), 
     type = "l", 
     xlim = c(-1,0),
     main = "Joint Confidence Region")
points(0,0)
points(coef(g)["pop15"], coef(g)["pop75"], 
       pch=18)
abline(v=confint(g)["pop15",], lty=2)
abline(h=confint(g)["pop75",], lty=2)
```

- Note the zero point is outside the **pop15** CI, inside the **pop75** CI
    + Only the one 95% CI for **pop15** rejects Null Hypothesis

- Note the zero point is outside the 95% CR
    + The joint 95% CR rejects the null hypothesis $H_0: \beta_{pop75} = \beta_{pop75} = 0$ 

- **The 95% CR is equivalent to testing the full model $y = pop15 + pop75 + dpi + ddpi$ versus the reduced model $y = dpi + ddpi$ using a level of significance equal to 5%**

</dev>

### Equivalent F-Test of $H_0: \beta_{pop75} = \beta_{pop75} = 0$   {.build}

```{r}
g1 <- lm(sr ~ dpi + ddpi, savings)
anova(g1, g)
```

Reject $H_0: \beta_{pop75} = \beta_{pop75} = 0$  since the _P-Value_ is less than 0.05

### Why an Ellipse? {.build}

The reason we get an ellipse and not a circle is because the estimators of the two coefficients are correlated, and hence their covariance is not zero

Check the correlation between $b_{pop15}$ and $b_{pop75}$

```{r, echo=TRUE, eval=TRUE, warning=FALSE}
summary(g, corr=TRUE)$corr
```

If thier correlation was zero, the CR would be a circle

### R Code for the CR Ellipse

```{r}
plot(ellipse(g, c("pop15", "pop75")), 
     type = "l", 
     xlim = c(-1,0),
     main = "Joint Confidence Region")
points(0,0)
points(coef(g)["pop15"], coef(g)["pop75"], 
       pch=18)
abline(v=confint(g)["pop15",], lty=2)
abline(h=confint(g)["pop75",], lty=2)
```

## 3D Scatterplot 

3D Scatterplots are useful for:

- Detecting outliers and influential points

- Understanding a confidence region for average and predicted response values

```{r, eval=TRUE, echo=FALSE, fig.height=6, fig.width=7, warning=FALSE}
# install.packages("scatterplot3d")
library("scatterplot3d")
attach(savings)
# scatterplot3d(pop15,pop75,sr, main="3D Scatterplot")
s3d <- scatterplot3d(pop15, pop75, sr, 
                     pch = 16, 
                     highlight.3d = TRUE, 
                     type = "h", 
                     main = "3D Scatterplot")
fit <- lm(sr ~ pop15 + pop75)
s3d$plane3d(fit)
detach(savings)
```



### R Code for 3D Scatterplot

```{r,echo=TRUE, eval=FALSE,  warning=FALSE}
install.packages("scatterplot3d")
library("scatterplot3d")
attach(savings)
# scatterplot3d(pop15,pop75,sr, main="3D Scatterplot")
s3d <- scatterplot3d(pop15,pop75,sr, 
                     pch=16, 
                     highlight.3d=TRUE, 
                     type="h", 
                     main="3D Scatterplot")
fit <- lm(sr ~ pop15 + pop75)
s3d$plane3d(fit)
detach(savings)
```

### 3D Spin-Plot {.build}

Spinning the 3D Scatterplot is better for detecting outliers and influential points than the static 3D Scatterplot alone

Run this code in the RStudio console to see the movie

```{r}
library("faraway")
library("rgl")
data(savings)
attach(savings)
plot3d(pop15, pop75, sr, 
       col="red", 
       size=3)
play3d(spin3d(axis = c(0, 0, 1)))
detach(savings)
```

## Confidence Intervals for One Predictive Value

Here we use the Galapagos data

Variable | Description
-------- | -----------
Species | the number of plant species found on the island
Endemics | the number of endemic species
Area | the area of the island (km$^2$)
Elevation | the highest elevation of the island (m)
Nearest | the distance from the nearest island (km)
Scruz | the distance from Santa Cruz island (km)
Adjacent | the area of the adjacent island (square km)

Source: M. P. Johnson and P. H. Raven (1973) "Species number and endemism: The Galapagos Archipelago revisited" Science, 179, 893-895

### CI for Response Value with the Full Model {.build}

```{r}
data(gala)
g <- lm(Species ~ Area + Elevation + Nearest +Scruz + Adjacent, gala)
```

Prepare a dataframe of one "new" island, the "prediction set"

```{r}
x0 <- data.frame(Area=0.08, Elevation=93, Nearest=6.0, Scruz=12, Adjacent=0.34)
```

Run both prediction methods, "confidence" and "prediction"

```{r}
rbind(predict(g, x0, interval="confidence"), 
      predict(g, x0, interval="prediction"))
```

### Compare confidence and prediction interval widths

```{r}
rbind(predict(g, x0, interval="confidence"), 
      predict(g, x0, interval="prediction"))
```

Prediction intervals are always wider than confidence intervals

### Predicting Outside the Boundary of the Data

Let's predict Species when Nearest moves away from the center of its data values

- As we move **Nearest** further away from the center of the date, the wider the intervals get

- This reflects the amount of uncertainlty incurred where there is no data

```{r}
data(gala)
g <- lm(Species ~ Area+Elevation+Nearest+Scruz+Adjacent,gala)
grid <- seq(0,100,1)
x0 <- data.frame(Area=0.08, Elevation=93,Nearest=grid,Scruz=12, Adjacent=0.14)
p <- predict(g, x0, se=T, interval="confidence")
matplot(grid, p$fit, lty=c(1,2,2), type="l", xlab="Nearest", ylab="Species")
rug(gala$Nearest)
```

</div>

### R Code for Prection outside the Boundary of the Data

```{r}
data(gala)
g <- lm(Species ~ Area+Elevation+Nearest+Scruz+Adjacent,gala)
grid <- seq(0,100,1)
x0 <- data.frame(Area=0.08, 
                 Elevation=93,
                 Nearest= grid,
                 Scruz=12, 
                 Adjacent=0.14)
p <- predict(g, x0, se = T, interval="confidence")
matplot(grid, p$fit, 
        lty = c(1,2,2), 
        type = "l", 
        xlab = "Nearest", 
        ylab = "Species")
rug(gala$Nearest)
```

## Example (Introducing Bonferroni)

### Prostate Data

This data frame contains the following columns:

Column    | Description
----------|------------
lcavol    | log(cancer volume)
lweight   | log(prostate weight)
age       | age
lbph      | log(benign prostatic hyperplasia amount)
svi       | seminal vesicle invasion (0 or 1)
lcp       | log(capsular penetration)
gleason   | Gleason score
pgg45     | percentage Gleason scores 4 or 5
lpsa      | log(prostate specific antigen)

Source: Andrews DF and Herzberg AM (1985): Data. New York: Springer-Verlag

### First Rows of Prostate Data

```{r}
data(prostate)
head(prostate, 10)
```

### Summary Table of Prostate Data

```{r}
summary(prostate)
```

### Fit All Predictors of **lpsa** With and Without  **gleason** as Factor

```{r}
g <- lm(lpsa ~ ., prostate)
summary(g)
```

### **gleason** as Factor

```{r}
g.gleason.as.factor <- lm(lpsa ~ lcavol + lweight + age + lbph + svi + lcp + as.factor(gleason) + pgg45, prostate)
summary(g.gleason.as.factor)
```

**as.factor(gleason)** requires three parameters to be estimated

- Which is a better fit, **gleason** as numeric, or as factor?

```{r}
anova(g, g.gleason.as.factor)
```

We accept Model 1 since the P-value is large

In other words, use **gleason** as a numeric variable


### One-at-a-time Confidence Intervals with Bonferroni Correction

We need a $1-\alpha$ family-wise confidence level

For $m$ simultaneous confidence intervals, the Bonferroni Correction to each individual CI level is a level equal to $1-\frac{\alpha}{2m}$

```{r}
m <- 8
level.fam <- .95
alpha <- (1-level.fam)
level.ind <- 1-alpha/(2*m)
```


```{r}
confint(g, level=level.ind)
```

CI's for **lcavol** and **svi** are the only ones that do not contain 0


- Compare Confidence Intervals of Coefficients without and with Bonferroni Correction Models 

```{r}
g  <- lm(lpsa ~ ., prostate)
g1 <- lm(lpsa ~ lcavol + 
           lweight +
           age + 
           lbph +
           svi +
           lcp + 
           as.factor(gleason) + 
           pgg45, 
         prostate)
g2 <- lm(lpsa ~ lcavol + svi, prostate)
```

- lm(lpsa ~ ., prostate)

```{r}
confint(g,  level=.95)
```

```{r}
confint(g,  level = 1 - 0.05/(2*8))
```


- lm(lpsa ~ lcavol + lweight + age + lbph + svi + lcp + as.factor(gleason) + pgg45, prostate)


```{r}
confint(g1, level=.95)
```

```{r}
confint(g1,  level = 1 - 0.05/(2*10))
```


- lm(lpsa ~ lcavol + svi, prostate)


```{r,tidy=TRUE}
confint(g2, level=.95)
```

```{r,tidy=TRUE}
confint(g2,  level = 1 - 0.05/(2*2))
```


- Joint Ellipse Confidence Region with Small Model

- Contruct the 95% joint confidence region for the coeffcients of **lcavol** and **svi** 

- Compare to the individual CI's for 95% level and the Bonferroni corrected level

```{r}
plot(ellipse(g2, c("lcavol", "svi"), 
     level= 0.95), 
     xlim = c(0,1), 
     ylim = c(0,2), 
     type="l",
     main = "Joint Confidence Region")
points(0,0)
points(g2$coef["lcavol"], g2$coef["svi"], pch=18)
abline(v=confint(g2,"lcavol"), lty=2)
abline(h=confint(g2,"svi"),    lty=2)
abline(v=confint(g2,"lcavol", level = 1 - 0.05/(2*2)), lty=2, col = "red")
abline(h=confint(g2,"svi",    level = 1 - 0.05/(2*2)), lty=2, col = "red")
```



```{r}
plot(ellipse(g2, c("lcavol", "svi"), 
     level= 0.95), 
     xlim = c(0,1), 
     ylim = c(0,2), 
     type="l",
     main = "Joint Confidence Region")
points(0,0)
points(g2$coef["lcavol"], g2$coef["svi"], pch=18)
abline(v=confint(g2,"lcavol"), lty=2)
abline(h=confint(g2,"svi"), lty=2)
abline(v=confint(g2,"lcavol", level = 1 - 0.05/(2*2)), lty=2, col = "red")
abline(h=confint(g2,"svi",    level = 1 - 0.05/(2*2)), lty=2, col = "red")
```

- All confidence intervals do not cover zero, so reject H0: all $\beta = 0$
- The intersection region of the 95% individual CI's appear to have less than 95% probabilty confidence coverage (black-dashed lines)
- While, the intersection region of the Bonferroni individual CI's have much more than 95% probabilty confidence coverage (red-dashed lines)

### 3D Scatterplot with Coloring and Vertical Lines and Regression Plane 

```{r}
library("scatterplot3d") 
attach(prostate) 
s3d <- scatterplot3d(lcavol, lweight, lpsa, 
                    pch=16, 
                    highlight.3d=TRUE, 
                    type="h", 
                    main="3D Scatterplot")
fit <- lm(lpsa ~ lcavol + lweight)
s3d$plane3d(fit)
detach(prostate)
```



```{r}
attach(prostate) 
s3d <- scatterplot3d(lcavol, lweight, lpsa, 
                    pch=16, 
                    highlight.3d=TRUE, 
                    type="h", 
                    main="3D Scatterplot")
fit <- lm(lpsa ~ lcavol + lweight)
s3d$plane3d(fit)
detach(prostate)
```

### Various 3D Spin-Plots

```{r}
attach(prostate) 
plot3d(lcavol, lweight, lpsa, 
       col  = "red", 
       size = 3)
play3d(spin3d(axis = c(0, 0, 1)))
plot3d(lcavol, lweight, lpsa, 
       col  = rainbow(97, end = 5/6)[rank(lpsa)], 
       size = 3)
play3d(spin3d(axis = c(0, 0, 1)))
rgl.spheres(lcavol, lweight, lpsa, 
            radius = .1,
            color  = rainbow(97))
play3d(spin3d(axis = c(0, 0, 1)))
detach(prostate)
```
 
### Confidence Intervals for Predicted Values

- Since **lpsa** is log'd, we may use the exp() function to get original units of measurement
- Make a prediction set of one point (ie. one record of predictor values)
- Compare intervals for log'd and orginal response values
```{r}
x0 <- data.frame(lcavol=1.22692, 
                 lweight=3.62301,  
                 age=40, 
                 lbph=0.3001, 
                 svi=0.0, 
                 lcp=-0.79851, 
                 gleason=7.0,  
                 pgg45=15.0) 
predict(g, 
        x0, 
        interval="prediction", 
        level=.95)
exp(predict(g, 
            x0, 
            interval="prediction", 
            level=.95))
```

### Confidence Intervals for Two Predicted Values

- Set up the predction set using two ages, 20 and 65

```{r}
# Compare two ages 20 and 60
x0 <- data.frame(lcavol=1.22692, 
                 lweight=3.62301,  
                 age=c(20, 65),    # Note this entry
                 lbph=0.3001,       
                 svi=0.0, 
                 lcp=-0.79851, 
                 gleason=7.0,  
                 pgg45=15.0) 
```


- Must use the **Bonferonni Correction** to the individual prediction level

```{r}
# Bonferroni Correction to individual level
m         <- 2
level.fam <- .95
alpha     <- 1-level.fam
level.ind <- 1-alpha/(2*m)
```


- The **lpsa** prediction widths look comparable between the two ages

```{r}
df <- data.frame(x0, predict(g, x0, interval = "prediction", level = level.ind))
subset(df, select=c("age", "fit", "lwr", "upr"))
```

- The **psa** prediction widths are huge and do not seem comparable between ages at all

```{r}
df <- data.frame(x0, exp(predict(g, x0, interval = "prediction", level = level.ind)))
subset(df, select=c("age", "fit", "lwr", "upr"))
```


## Lab Exercise

### Confidence Intervals

We review some confidence interval procedures that are relevant to making decisions with predictive models.

### Data | uswages

We consider the dataset on Weekly wages of US male workers in 1988.

```{r}
library(faraway)
data("uswages")
?uswages
```

### Load Data

Here we load the relevant library and the data into memory.

```{r}
# load data
library("faraway")
data(uswages)
head(uswages)
```

Now we preprocess the data.

```{r}
# load data
data("uswages")

# manipulating data
# we see that exper has neg. values
uswages$exper[uswages$exper <0] <-NA

# convert race, smsa, and pt to factor variables
uswages$race <- factor(uswages$race)
levels(uswages$race) <- c("White","Black")
uswages$smsa <- factor(uswages$smsa)
levels(uswages$smsa) <- c("No","Yes")
uswages$pt <- factor(uswages$pt)
levels(uswages$pt) <- c("No","Yes")

# create region, a factor variable based on the four regions ne, mw, so, we
uswages <- data.frame(uswages,
                      region =
                        1*uswages$ne +
                        2*uswages$mw +
                        3*uswages$so +
                        4*uswages$we)
uswages$region <- factor(uswages$region)
levels(uswages$region) <- c("ne","mw","so","we")

# We are skipping these steps
# # delete the four regions ne, mw, so, we
# uswages <- subset(uswages,select=-c(ne:we))

# Take care of NAs
uswages <- na.omit(uswages)

# Column names
names(uswages)
```

### One at a time confidence intervals

For coefficients of a particular model, the easiest way is using the the `confint` function.

Consider the regression model:

### 1. Lab: Show that the one-at-a-time 95% confidence interval for each parameter is:

```{r}
g <- lm(log(wage) ~ educ + exper + race + smsa + pt + region, data = uswages)
confint(g, level = 0.95)
```

We see that the confidence intervals for the `region` indicator variables each contain $0$. Let's do a proper Partial F-test to see if we can drop `region` from the model.

### 2. Lab: Show that the F-test ANOVA results are the following:

```{r}
g1 <- lm(log(wage) ~ educ + exper + race + smsa + pt, data = uswages)
anova(g1, g)

```

We see that the F-ratio is very small, `r anova(g1, g)$F[2]` with P-value `r anova(g1, g)$P[2]`. 

### 3. Lab: Show why or why not the conclusion then is to accept the small model by removing `region` from the model, in accordance with the indication provided by the confidence intervals.

> The *take-away*: When we see confidence intervals crossing the number $0$ for two or more variables, we always perform a partial F-test to affirm taking these variables from the model.  

### Joint confidence intervals

Now we construct the joint 95% confidence region for $\beta_{educ}$  and $\beta_{exper}$. 


### 4. Lab: Obtain and  show that the 95% confidence region is the following .

```{r}
library(ellipse)
plot(ellipse(g1,c(2,3)), type="l") 
# 
points(0,0) 
points(coef(g1)[2], coef(g1)[3], pch=18)
```


### 5. Lab: Show that the origin is outside the ellipse, we reject the hypothesis $H_0:\beta_{educ} = \beta_{exper} = 0$.

### 6. Lab: Obtain and and show this with a partial F-test:

```{r}
g2 <- lm(log(wage) ~ race + smsa + pt, data = uswages)
anova(g2, g1)
```

### Confidence intervals for prediction

Now we wish to predict the mean response of log(wage) for a particular configuration of predictor variables using the model:

Let's say we want to predict log(wage) for white, full-time, high-school graduates with five years experience living in a statistical metropolitan area.

We put the new configuration into a new dataframe with just one row:

```{r}
x0 <- data.frame(educ=12,
                 exper=5,
                 race="White",
                 smsa="Yes",
                 pt="No", 
                 stringsAsFactors = FALSE)
```

### 7. Lab: Show that the prediction interval  with a 95% confidence for the mean response is:

```{r}
predict(g1, x0, level = 0.95, interval = "confidence")
```

This is a fairly tight prediction with range of just 0.05 on the log scale.

Now let's do another prediction for mean log(wage) for a black worker with everything else the same. We will just add another row to the data frame x0.

```{r}
x0 <- rbind(x0, 
            data.frame(educ=12, 
                 exper=5, 
                 race="Black", 
                 smsa="Yes", 
                 pt="No")
)
```

### 8. Lab: Show that the prediction interval  with a 95% confidence for the mean response is:

```{r}
(pred <- predict(g1, x0, level = 0.95, interval = "confidence"))
```

So we see that a Black person's wage is significantly less than a White person's wage with the same education, experience, etc.

### R Note

When we predict using categorical variables we must use the parameter "stringsAsFactors = FALSE" when we create a dataframe for the new data. If we did not specify how the string values were to be treated, R would create a new factor with levels that would not match the levels of our original (training) data.

### Prediction on the original scale

Up to now, we have been modeling using log(wage). Suppose we want the predictions in the original scale? Fortunately this is easy. We just use the inverse of the transform on the fitted value, upper and lower limits of the confidence intervals:

```{r}
exp(pred)
```

## Exercises

### 1. Exercise

For the `prostate` data in`faraway`, fit a model with `lpsa` as the response and the other variables as predictors.

Compute 90% and 95% CIs for the parameter associated with `age` 

```{r}
library("faraway")
data("prostate")
g <- lm(lpsa ~ ., data = prostate)
confint(g, level = 0.90)
confint(g, level = 0.95)
```

### 2. Exercise

Compute and display a 95% joint confidence region for the parameters associated with `age` and `lbph`. Plot the origin and report the outcome of the appropriate hypotheses test. Affirm this conclusion with an appropriate partial F-test.

```{r}
library(ellipse)
plot(ellipse(g,c(4,5)), type="l") 
points(0,0) 
points(coef(g)[4], coef(g1)[5], pch=18)
g1 <- lm(lpsa ~ . - age - lbph, data = prostate)
anova(g1, g)
```

### 3. Exercise

Predict `lpsa` (95%) for a new patient with `lcavol` = 1.22692, `lweight` = 3.62301, `age` = 65, `lbph` = -0.3001, `svi` = 0.0, `lcp` = -0.79851, `gleason` = 7.0, `pgg45` = 15.0. Do this again for the mean response. Using the `exp()` function, obtain the  new prediction and mean response for `psa`.

```{r}
x0 <- data.frame(lcavol = 1.22692, 
                 lweight = 3.62301,                  age = 65, 
                 lbph = -0.3001, 
                 svi = 0.0, 
                 lcp = -0.79851, 
                 gleason = 7.0, 
                 pgg45 = 15.0)
predict_prediction_g_lpsa <- predict(g, x0, level = 0.95, interval = "prediction")
predict_confidence_g_lpsa <- predict(g, x0, level = 0.95, interval = "confidence")
predict_prediction_g_psa <- exp(predict_prediction_g_lpsa)
predict_confidence_g_psa <- exp(predict_confidence_g_lpsa)
result_g_65 <- rbind(predict_prediction_g_lpsa,
        predict_confidence_g_lpsa,
        predict_prediction_g_psa,
        predict_confidence_g_psa)
row.names(result_g_65) <-
  c("predict_prediction_g_lpsa",
    "predict_confidence_g_lpsa",
    "predict_prediction_g_65_psa",
    "predict_confidence_g_65_psa")
result_g_65
```

### 4. Exercise

Repeat the above exercise with new patient `age` = 20

```{r}
x0 <- data.frame(lcavol = 1.22692, 
                 lweight = 3.62301, 
                 age = c(65,20), 
                 lbph = -0.3001, 
                 svi = 0.0, 
                 lcp = -0.79851, 
                 gleason = 7.0, 
                 pgg45 = 15.0)
predict_prediction_g_lpsa <- predict(g, x0, level = 0.95, interval = "prediction")
predict_confidence_g_lpsa <- predict(g, x0, level = 0.95, interval = "confidence")
predict_prediction_g_psa <- exp(predict_prediction_g_lpsa)
predict_confidence_g_psa <- exp(predict_confidence_g_lpsa)
result_g <- rbind(predict_prediction_g_lpsa,
                  predict_confidence_g_lpsa,
                  predict_prediction_g_psa,
                  predict_confidence_g_psa)
row.names(result_g) <- c("predict_prediction_g_lpsa_65",
                         "predict_prediction_g_lpsa_20",
                         "predict_confidence_g_lpsa_65",
                         "predict_confidence_g_lpsa_20",
                         "predict_prediction_g_psa_65",
                         "predict_prediction_g_psa_20",
                         "predict_confidence_g_psa_65",
                         "predict_confidence_g_psa_20")
result_g
```
### 5. Exercise

For the model in exercise 1, remove all the predictors that are not significant at the 5% level.

```{r}
summary(g)
g2 <- lm(lpsa~. -lcp -gleason -pgg45, data = prostate)
```

Recompute the predictions for exercises 3 and 4. Compare CIs. On the `psa` scale, which CIs do you prefer?

```{r}
x0 <- data.frame(lcavol = 1.22692, 
                 lweight = 3.62301, 
                 age = c(65,20),
                 lbph = -0.3001, 
                 svi = 0.0, 
                 lcp = -0.79851, 
                 gleason = 7.0, 
                 pgg45 = 15.0)
predict_prediction_g2_lpsa <- 
  predict(g2, x0, 
          level = 0.95, 
          interval = "prediction")
predict_confidence_g2_lpsa <- 
  predict(g2, x0, 
          level = 0.95, 
          interval = "confidence")
predict_prediction_g2_psa <-
  exp(predict_prediction_g2_lpsa)
predict_confidence_g2_psa <-
  exp(predict_confidence_g2_lpsa)
result <- rbind(predict_prediction_g_psa,
                   predict_confidence_g_psa,
                   predict_prediction_g2_psa,
                   predict_confidence_g2_psa)
row.names(result) <-
  c("predict_prediction_g_psa_65",
    "predict_prediction_g_psa_20",
    "predict_confidence_g_psa_65",
    "predict_confidence_g_psa_20",
    "predict_prediction_g2_psa_65",
    "predict_prediction_g2_psa_20",
    "predict_confidence_g2_psa_65",
    "predict_confidence_g2_psa_20")
result
```

### 6. Exercise

Test the "small" model in exercise 5 against the "big""  model in exercise 1 at *probability type I error* $\alpha = 0.05$. Which model is preferred?

```{r}
anova(g2, g)
```



